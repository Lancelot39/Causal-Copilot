User original query (TOP PRIORITY):
Discover causal relationships between protein signaling molecules. The data contains flow cytometry measurements of proteins and phospholipids.

The computation has to be finished in the runtime of 1440.0 minutes.

## ⚠️ ESSENTIAL QUERY PRIORITY ⚠️
- User query SUPERSEDES all standard hyperparameter guidelines
- Extract specific needs, constraints, domain insights from user query FIRST
- Parameters MUST be adjusted to meet user's explicit requirements 
- ALL recommendations MUST directly align with the user's stated objectives
- User domain knowledge overrides general optimization guidelines

-----------------------------------------------
Given a dataset with the following properties:

1. Columns: Raf	Mek	Plcg	PIP2	PIP3	Erk	Akt	PKA	PKC	P38	Jnk
2. Statistics:
The dataset has the following characteristics:

Data Type: The overall data type is Continuous.

The sample size is 853 with 11 features. 

This dataset is not time-series data. 

Data Quality: There are no missing values in the dataset.

Statistical Properties:
- Linearity: The relationships between variables are not linear.
- Gaussian Errors: The errors in the data do not follow a Gaussian distribution.
- Heterogeneity: The dataset is not heterogeneous. 




3. Background Knowledge:
T
h
i
s
 
i
s
 
f
a
k
e
 
d
o
m
a
i
n
 
k
n
o
w
l
e
d
g
e
 
f
o
r
 
d
e
b
u
g
g
i
n
g
 
p
u
r
p
o
s
e
s
.

We have selected the following algorithm for causal discovery:

Algorithm: FCI

Now, we need to determine the optimal hyperparameters for this algorithm. I'll guide you through a systematic approach to select values that prioritize accuracy while maintaining computational efficiency for moderate graph sizes.

Primary hyperparameters to configure: alpha, indep_test, depth

For each hyperparameter, please follow this structured approach:

Step 1: Understand the dataset characteristics
   - Consider the number of variables (graph size)
   - Analyze sample size and data distribution
   - Note if data is linear/nonlinear, continuous/discrete/mixed
   - For time-series data, prioritize the statistically estimated lag order

Step 2: Assess computational resources
   - Consider the hardware constraints and GPU availability:
   
Current machine doesn't support CUDA, do not choose any GPU-powered algorithms.

   - Prioritize to GPU implemented hyperparameter when dealing with large graph (variable size > 150) to achieve more efficient speedup

Step 3: Evaluate each hyperparameter's impact on accuracy vs. efficiency
   - Critical parameters affecting accuracy (e.g., significance levels, independence tests)
   - Parameters affecting computational complexity (e.g., search depth, maximum conditions)
   - Parameters controlling sparsity (e.g., regularization, thresholds)

Step 4: Analyze algorithm-specific recommendations
   - Review expert suggestions for each parameter:
   "**Parameter:** alpha\n- **Meaning:** Desired significance level in (0, 1)\n- **Available Values:**\n  - 0.05\n  - 0.1\n  - 0.01\n- **Expert Suggestion:** Use 0.05 as default. Adjust based on sample size, more conservative (lower) values for larger samples. If < 500, use 0.1; Else if 500-10000 (<10000 but >500), use 0.05; Else if > 10000, using 0.01.\n\n**Parameter:** indep_test\n- **Meaning:** Independence test method\n- **Available Values:**\n  - fisherz\n  - chisq\n  - kci\n  - fastkci\n  - rcit\n- **Expert Suggestion:** Use fisherz as default (for linear data). Choose based on data type, DON'T use nonlinear/non-parametric tests for linear/discrete data.\n\nLINEAR/DISCRETE (PARAMETRIC) TESTS:\n- 'fisherz': For linear continuous data (default choice for linear data)\n- 'chisq': For discrete data only (applied only for pure discrete data)\n\nNONLINEAR/NON-PARAMETRIC TESTS:\n- 'kci': For nonlinear data (very slow, use only if variable size < 10 and sample size < 1500)\n- 'rcit': Fastest approximation of kci for non-linear data (use only if variable size < 100 and sample size < 10000)\n- 'fastkci': Divide-and-conquer version of kci for non-linear data, faster than kci but less accurate (use only if variable size < 20 and sample size < 3000)\n\nFor nonlinear data, as long as variable and sample size constraints are fulfilled, choose in order of accuracy: KCI > RCIT > FastKCI.\n\n**Parameter:** depth\n- **Meaning:** Maximum depth for skeleton search\n- **Available Values:**\n  - -1\n  - 6\n  - 4\n  - 2\n  - 1\n- **Expert Suggestion:** Use -1 as default. Use -1 for unlimited depth. For large graphs, limiting depth (e.g., 1-3) can significantly speed up the algorithm at the cost of some accuracy. A graph with node number < 10, use depth 6; A graph with node number 10 - 25, use depth 4; A graph with node number 25-50, use depth 2; A graph with node number > 50, use depth 1.\n\n"

Step 5: Analyze algorithm performance with different hyperparameter configurations (If existed)
   - Review benchmarking results for this algorithm with various hyperparameter settings
   - Identify which configurations perform best on datasets with similar characteristics
   - Consider how different hyperparameter values affect performance metrics
   - Analyze the trade-offs between accuracy and computational efficiency

# ALGORITHM BENCHMARKING RESULTS

• CAUTIONARY NOTE
  – These benchmarking results should be used as guidelines, not definitive judgments
  – Performance may vary significantly with real-world data compared to simulations
  – Consider your specific domain knowledge and data characteristics when selecting algorithms
• Simulation Settings
  – Network sizes: 5 to 1000 nodes
  – Sample sizes: 500 to 10000 data points
  – Edge density: 0.11 to 0.78 probability (avg. degree 1 to 7)
  – Data types: Continuous and mixed (0-20% discrete variables)
  – Function types: Linear and non-linear (MLP) relationships
  – Noise types: Gaussian and uniform distributions

• Challenge Scenarios
  – Measurement error: 10%, 30%, 50% noise in observations
  – Missing data: 10%, 20%, 30% missing values
  – Multi-domain data: 1, 2, 5, or 10 heterogeneous domains
  – Each configuration tested with 3 different random seeds

• Key Terms
  – (linear): Scenarios where relationships between variables follow linear functions
  – (mlp): Scenarios where relationships are non-linear (using multilayer perceptron models)

• Scenario Types
  – Robustness scenarios (e.g., Variable Scaling, Edge Probability): Test algorithm performance across varying levels of a property
  – Specific scenarios (e.g., Gaussian Noise, Dense Graph): Test performance at a fixed specific setting

• Performance Metrics
  – Performance level (1-10): Based on F1 score, higher is better
  – Efficiency level (0-5): Based on runtime, higher is better (only relevant for scaling scenarios)
  – Stability: Standard deviation of performance, lower values indicate more consistent results

• Important Note on Efficiency Scoring
  – Benchmarks include large-scale systems with up to 1000 nodes and may timeout for some algorithms
  – For large-scale systems (node size > 200), prioritize algorithms that can utilize available GPUs
  – GPU-accelerated methods provide significant efficiency advantages in large-scale scenarios

────────────────────────────────────────────────────────
Filtered Benchmarking Results
────────────────────────────────────────────────────────

Algorithms included: FCI

────────────────────────────────────────────────────────
Overall Algorithm Performance
────────────────────────────────────────────────────────

Overall ranking based on average performance across all scenarios:

1. FCI_indep_test=fisherz: 7.4
2. FCI_indep_test=rcit: 7.3
3. FCI_indep_test=kci: 6.2
4. FCI_indep_test=fastkci: 6.2


────────────────────────────────────────────────────────
Efficiency Comparison
────────────────────────────────────────────────────────

Note: Efficiency scores are primarily measured in Variable Scaling and Sample Scaling scenarios.

| Algorithm | Variable Scaling (linear) | Sample Scaling (linear) | Variable Scaling (mlp) | Sample Scaling (mlp) | Average |
|-----------|---------------------------|--------------------------|------------------------|----------------------|--------|
| FCI_indep_test=fisherz | 4.7 | N/A | 4.7 | N/A | 4.7 |
| FCI_indep_test=kci | 3.7 | N/A | 4.1 | N/A | 3.9 |
| FCI_indep_test=fastkci | 3.4 | N/A | 4.1 | N/A | 3.8 |
| FCI_indep_test=rcit | 3.3 | N/A | 4.0 | N/A | 3.6 |


────────────────────────────────────────────────────────
Algorithm Recommendations by Scenario Type
────────────────────────────────────────────────────────

• Linear Relationships
  1. FCI_indep_test=fisherz: Performance 7.8
  2. FCI_indep_test=rcit: Performance 7.7
  3. FCI_indep_test=kci: Performance 6.8

• Non-Linear Relationships
  1. FCI_indep_test=fisherz: Performance 6.9
  2. FCI_indep_test=rcit: Performance 6.6
  3. FCI_indep_test=kci: Performance 5.4

• Data with Missing Values
  1. FCI_indep_test=rcit: Performance 7.6
  2. FCI_indep_test=fisherz: Performance 7.3
  3. FCI_indep_test=kci: Performance 6.3

• Data with Measurement Error
  1. FCI_indep_test=rcit: Performance 8.1
  2. FCI_indep_test=fisherz: Performance 8.0
  3. FCI_indep_test=fastkci: Performance 7.8

• Dense vs Sparse Graphs
  1. FCI_indep_test=rcit: Performance 6.7
  2. FCI_indep_test=fisherz: Performance 6.4
  3. FCI_indep_test=fastkci: Performance 5.3

• Heterogeneous Data
  1. FCI_indep_test=fisherz: Performance 6.7
  2. FCI_indep_test=rcit: Performance 6.2
  3. FCI_indep_test=kci: Performance 5.4


────────────────────────────────────────────────────────
Performance by Scenario
────────────────────────────────────────────────────────

### ROBUSTNESS SCENARIOS
These scenarios test algorithm performance across varying levels of a property.


• Variable Scaling (linear)
| Algorithm | Performance | Stability | Efficiency | Overall Score |
|-----------|------------|-----------|------------|-------------|
| FCI_indep_test=rcit | 8.3 | 6.3 | 3.3 | 7.8 |
| FCI_indep_test=fisherz | 8.1 | 3.3 | 4.7 | 7.6 |
| FCI_indep_test=kci | 7.3 | 7.9 | 3.7 | 7.1 |
| FCI_indep_test=fastkci | 7.2 | 5.8 | 3.4 | 7.0 |

• Sample Scaling (linear)
| Algorithm | Performance | Stability | Efficiency | Overall Score |
|-----------|------------|-----------|------------|-------------|
| FCI_indep_test=fisherz | 9.2 | 7.2 | N/A | 9.2 |
| FCI_indep_test=rcit | 9.0 | 7.8 | N/A | 9.0 |
| FCI_indep_test=fastkci | 8.6 | 7.7 | N/A | 8.6 |
| FCI_indep_test=kci | 8.5 | 9.5 | N/A | 8.5 |

• Heterogeneity (linear)
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=fisherz | 8.5 | 1.6 |
| FCI_indep_test=rcit | 8.0 | 2.1 |
| FCI_indep_test=kci | 7.2 | 3.6 |
| FCI_indep_test=fastkci | 7.2 | 0.5 |

• Measurement Error (linear)
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=fisherz | 9.1 | 10.2 |
| FCI_indep_test=rcit | 8.9 | 5.3 |
| FCI_indep_test=fastkci | 8.8 | 5.3 |
| FCI_indep_test=kci | 8.5 | 8.1 |

• Noise Type (linear)
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=fisherz | 9.6 | 4.5 |
| FCI_indep_test=rcit | 8.9 | 1.5 |
| FCI_indep_test=kci | 7.1 | 9.5 |
| FCI_indep_test=fastkci | 7.0 | 5.5 |

• Missing Data (linear)
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=fisherz | 8.0 | 3.4 |
| FCI_indep_test=rcit | 7.9 | 4.4 |
| FCI_indep_test=kci | 6.3 | 9.5 |
| FCI_indep_test=fastkci | 6.2 | 5.9 |

• Edge Probability (linear)
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=rcit | 6.9 | 9.4 |
| FCI_indep_test=fisherz | 6.7 | 6.4 |
| FCI_indep_test=fastkci | 5.8 | 6.9 |
| FCI_indep_test=kci | 5.7 | 6.9 |

• Discrete Ratio (linear)
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=fisherz | 7.6 | 2.9 |
| FCI_indep_test=kci | 6.9 | 3.1 |
| FCI_indep_test=rcit | 6.8 | 1.6 |
| FCI_indep_test=fastkci | 6.8 | 7.8 |

• Variable Scaling (mlp)
| Algorithm | Performance | Stability | Efficiency | Overall Score |
|-----------|------------|-----------|------------|-------------|
| FCI_indep_test=rcit | 6.7 | 9.0 | 4.0 | 6.4 |
| FCI_indep_test=fisherz | 6.0 | 6.0 | 4.7 | 5.8 |
| FCI_indep_test=kci | 5.1 | 10.5 | 4.1 | 5.0 |
| FCI_indep_test=fastkci | 4.8 | 3.0 | 4.1 | 4.8 |

• Sample Scaling (mlp)
| Algorithm | Performance | Stability | Efficiency | Overall Score |
|-----------|------------|-----------|------------|-------------|
| FCI_indep_test=rcit | 8.1 | 3.2 | N/A | 8.1 |
| FCI_indep_test=fisherz | 7.3 | 9.0 | N/A | 7.3 |
| FCI_indep_test=kci | 5.5 | 11.1 | N/A | 5.5 |
| FCI_indep_test=fastkci | 5.3 | 4.0 | N/A | 5.3 |

• Heterogeneity (mlp)
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=fisherz | 6.2 | 5.4 |
| FCI_indep_test=rcit | 6.0 | 3.3 |
| FCI_indep_test=kci | 4.6 | 5.3 |
| FCI_indep_test=fastkci | 4.6 | 5.3 |

• Measurement Error (mlp)
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=fisherz | 6.9 | 9.4 |
| FCI_indep_test=rcit | 6.6 | 2.8 |
| FCI_indep_test=fastkci | 5.2 | 4.3 |
| FCI_indep_test=kci | 5.1 | 3.5 |

• Noise Type (mlp)
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=fisherz | 8.1 | 1.5 |
| FCI_indep_test=rcit | 6.5 | 2.5 |
| FCI_indep_test=fastkci | 6.1 | 9.0 |
| FCI_indep_test=kci | 6.1 | 8.5 |

• Missing Data (mlp)
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=fisherz | 6.8 | 4.5 |
| FCI_indep_test=kci | 6.8 | 10.4 |
| FCI_indep_test=fastkci | 6.3 | 7.8 |
| FCI_indep_test=rcit | 6.2 | 4.4 |

• Edge Probability (mlp)
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=rcit | 7.0 | 4.6 |
| FCI_indep_test=fisherz | 6.9 | 6.8 |
| FCI_indep_test=kci | 5.2 | 8.1 |
| FCI_indep_test=fastkci | 5.1 | 5.7 |

• Discrete Ratio (mlp)
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=fisherz | 8.4 | 0.0 |
| FCI_indep_test=rcit | 6.2 | 0.0 |
| FCI_indep_test=kci | 5.8 | 0.0 |
| FCI_indep_test=fastkci | 5.8 | 0.0 |

### SPECIFIC SCENARIOS
These scenarios test algorithm performance at specific settings rather than variable levels.


• Linear Function
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=rcit | 6.2 | 0.0 |
| FCI_indep_test=fisherz | 6.2 | 0.0 |
| FCI_indep_test=fastkci | 6.0 | 0.0 |
| FCI_indep_test=kci | 6.0 | 0.0 |

• Non-Linear Function
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=rcit | 6.0 | 0.0 |
| FCI_indep_test=fisherz | 5.1 | 0.0 |
| FCI_indep_test=kci | 4.8 | 0.0 |
| FCI_indep_test=fastkci | 4.0 | 0.0 |

• Gaussian Noise
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=fisherz | 9.6 | 0.0 |
| FCI_indep_test=kci | 8.4 | 0.0 |
| FCI_indep_test=rcit | 8.3 | 0.0 |
| FCI_indep_test=fastkci | 8.2 | 0.0 |

• Non-Gaussian Noise
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=rcit | 9.5 | 0.0 |
| FCI_indep_test=fisherz | 9.5 | 0.0 |
| FCI_indep_test=kci | 5.8 | 0.0 |
| FCI_indep_test=fastkci | 5.8 | 0.0 |

• Dense Graph
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=rcit | 4.7 | 0.0 |
| FCI_indep_test=fisherz | 4.6 | 0.0 |
| FCI_indep_test=kci | 2.6 | 0.0 |
| FCI_indep_test=fastkci | 2.6 | 0.0 |

• Sparse Graph
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=rcit | 8.3 | 0.0 |
| FCI_indep_test=fastkci | 7.7 | 0.0 |
| FCI_indep_test=fisherz | 7.6 | 0.0 |
| FCI_indep_test=kci | 7.4 | 0.0 |

• High Missing Data
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=rcit | 8.8 | 0.0 |
| FCI_indep_test=fisherz | 7.2 | 0.0 |
| FCI_indep_test=kci | 5.9 | 0.0 |
| FCI_indep_test=fastkci | 5.6 | 0.0 |

• High Measurement Error
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=kci | 9.5 | 0.0 |
| FCI_indep_test=fastkci | 9.5 | 0.0 |
| FCI_indep_test=rcit | 8.6 | 0.0 |
| FCI_indep_test=fisherz | 8.0 | 0.0 |

• Highly Mixed Data
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=fisherz | 5.0 | 0.0 |
| FCI_indep_test=rcit | 3.9 | 0.0 |
| FCI_indep_test=kci | 3.8 | 0.0 |
| FCI_indep_test=fastkci | 3.8 | 0.0 |

• Highly Heterogeneous
| Algorithm | Performance | Stability |
|-----------|------------|----------|
| FCI_indep_test=fisherz | 7.3 | 0.0 |
| FCI_indep_test=rcit | 6.8 | 0.0 |
| FCI_indep_test=kci | 6.2 | 0.0 |
| FCI_indep_test=fastkci | 6.2 | 0.0 |


-------------------------------------------

Step 6: Make final decisions based on:
   - For moderate graph sizes (<50 variables), prioritize accuracy over speed
   - For large graphs (>50 variables), balance accuracy with feasibility and EFFICIENCY
   - For time-series data, carefully consider temporal parameters

Please provide your suggestions in a structured JSON format, with detailed reasoning for each hyperparameter. Your response should look like this:

{
  "algorithm": "PC",
  "hyperparameters": {
    "[HYPERPARAMETER_1_NAME]": {
      "full_name": "[HYPERPARAMETER_1_FULL_NAME]",
      "reasoning": "[YOUR_STEP_BY_STEP_REASONING_PROCESS]",
      "value": [SUGGESTED_VALUE],
      "explanation": "[BRIEF_EXPLANATION_OF_TRADEOFFS]"
    },
    "[HYPERPARAMETER_2_NAME]": {
      "full_name": "[HYPERPARAMETER_2_FULL_NAME]",
      "reasoning": "[YOUR_STEP_BY_STEP_REASONING_PROCESS]",
      "value": [SUGGESTED_VALUE],
      "explanation": "[BRIEF_EXPLANATION_OF_TRADEOFFS]"
    }
  }
}

Important guidelines:
1. Only select values from the "available_values" list for each hyperparameter
2. For moderate graph sizes (10-50 variables), prioritize accuracy over speed
3. For time-series data, give special attention to lag parameters based on statistical estimates
4. Consider independence test selection carefully based on data type and computational resources
5. For regularization parameters, consider the expected graph density
6. For search depth parameters, consider the complexity of potential causal relationships

Please provide your hyperparameter suggestions following this JSON structure, with clear reasoning that demonstrates you've considered the dataset characteristics, algorithm requirements, and computational constraints.